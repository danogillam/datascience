{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "### Dano Gillam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed_data = np.loadtxt('/home/danogillam/databases/seeds_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_data.shape =  (210, 8)\n"
     ]
    }
   ],
   "source": [
    "print 'seed_data.shape = ', seed_data.shape\n",
    "D = seed_data.shape[0] #D : dataset size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['area','perimeter','compactness','length',\n",
    "            'width','asymmetry_coefficient','groove_length']\n",
    "label = ['species']\n",
    "seeds = pd.DataFrame(seed_data,columns=features+label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>asymmetry_coefficient</th>\n",
       "      <th>groove_length</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length  width  asymmetry_coefficient  \\\n",
       "0  15.26      14.84       0.8710   5.763  3.312                  2.221   \n",
       "1  14.88      14.57       0.8811   5.554  3.333                  1.018   \n",
       "2  14.29      14.09       0.9050   5.291  3.337                  2.699   \n",
       "3  13.84      13.94       0.8955   5.324  3.379                  2.259   \n",
       "4  16.14      14.99       0.9034   5.658  3.562                  1.355   \n",
       "\n",
       "   groove_length  species  \n",
       "0          5.220        1  \n",
       "1          4.956        1  \n",
       "2          4.825        1  \n",
       "3          4.805        1  \n",
       "4          5.175        1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select a test set and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ind = np.random.choice(D,replace=False,size=40)\n",
    "train_ind = list(set(range(D)).difference(test_ind))\n",
    "\n",
    "train = seeds.iloc[train_ind]\n",
    "test = seeds.iloc[test_ind][features]\n",
    "test_labels  = seeds.iloc[test_ind][label].values.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the mean of each feature of each label in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 7)\n"
     ]
    }
   ],
   "source": [
    "train_label_means = [train[features][train.species==i].mean() for i in xrange(1,4)]\n",
    "train_label_means\n",
    "print np.shape(train_label_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the variance of each feature of each label in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 7)\n"
     ]
    }
   ],
   "source": [
    "train_label_variances = [train[features][train.species==i].var() for i in xrange(1,4)]\n",
    "print np.shape(train_label_variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "prediction1 = []\n",
    "#iterate datapoints\n",
    "for X in test.values:\n",
    "    prediction1.append(np.argmax([sum(\n",
    "                                    [norm.logpdf(x,loc=mu,scale=sig) for x,mu,sig \n",
    "                                    in zip(X,train_label_means[i],train_label_variances[i])]\n",
    "                                ) for i in xrange(3)])+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predictions to correct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_labels==prediction1)/40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn to perform naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "alg = GaussianNB()\n",
    "alg.fit(train[features],train.species)\n",
    "prediction2 = alg.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predictions with correct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94999999999999996"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_labels==prediction2)/40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5172\n",
      "5172\n",
      "8167\n",
      "(2, 8167)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from scipy.stats import norm\n",
    "\n",
    "def naivebayes(P,X,means,variances,n_labels):\n",
    "    return np.argmax([ P[i] + sum(\n",
    "                [norm.logpdf(x,loc=mu,scale=sig) for x,mu,sig \n",
    "                in zip(X,means[i],variances[i])]\n",
    "            ) for i in xrange(n_labels)])\n",
    "\n",
    "class NaiveBayes():\n",
    "    def __init__(self):\n",
    "        \n",
    "        print 'Loading SpamFeatures...',\n",
    "        try: self.docs = np.load('/home/danogillam/databases/spamtext/SpamFeatures')\n",
    "        except:\n",
    "            feature_filename = '/home/danogillam/databases/spamtext/SpamFeatures.txt'\n",
    "            self.docs = np.genfromtxt(feature_filename)\n",
    "            np.save('/home/danogillam/databases/spamtext/SpamFeatures',self.docs)\n",
    "        self.D = len(self.docs)\n",
    "        \n",
    "        print '\\rLoading SpamLabels...',\n",
    "        try: self.labels = np.load('/home/danogillam/databases/spamtext/SpamLabels')\n",
    "        except:\n",
    "            labels_filename = '/home/danogillam/databases/spamtext/SpamLabels.txt'\n",
    "            self.labels = np.genfromtxt(labels_filename)\n",
    "            np.save('/home/danogillam/databases/spamtext/SpamLabels',self.labels)\n",
    "        self.L = len(self.labels)\n",
    "        \n",
    "        print '\\rLoading SpamVocab...',\n",
    "        try: self.vocab = np.load('/home/danogillam/databases/spamtext/SpamVocab')\n",
    "        except:\n",
    "            vocab_filename = '/home/danogillam/databases/spamtext/SpamVocab.txt'\n",
    "            self.vocab =  np.genfromtxt(vocab_filename)\n",
    "            np.save('/home/danogillam/databases/spamtext/SpamVocab',self.vocab)\n",
    "        self.V = len(self.vocab)\n",
    "        \n",
    "        print '\\rSplitting data...',\n",
    "        train, test, train_labels, test_labels = self._split_data()\n",
    "        self.train = train\n",
    "        self.test  = test\n",
    "        self.train_labels = train_labels\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "        print '\\rFinding means and variances...',\n",
    "        self.train_label_means = np.array([train[train_labels==i].mean(axis=0) for i in np.unique(train_labels)])\n",
    "        self.train_label_vars  = np.array([train[train_labels==i].var(axis=0)  for i in np.unique(train_labels)])\n",
    "        print '\\r',\n",
    "        \n",
    "        self.P = np.unique(self.labels,return_counts=True)[1]\n",
    "        \n",
    "        \n",
    "    def _split_data(self,testsize=500):\n",
    "        test_ind = np.random.choice(self.D,replace=False,size=testsize)\n",
    "        train_ind = list(set(range(self.D)).difference(test_ind))\n",
    "\n",
    "        train = self.docs[train_ind]\n",
    "        test = self.docs[test_ind]\n",
    "        \n",
    "        train_labels = self.labels[train_ind]\n",
    "        test_labels  = self.labels[test_ind]\n",
    "        return train, test, train_labels, test_labels\n",
    "    \n",
    "    def naivebayes_predict(self):\n",
    "        \n",
    "        #iterate datapoints\n",
    "        for it,X in enumerate(self.test):\n",
    "            print '\\r',it,\n",
    "            prediction1.append(self._naivebayes(X))\n",
    "        print np.sum(self.test_labels==prediction1)/len(self.test_labels)\n",
    "        return prediction1\n",
    "    \n",
    "    def _naivebayes(self,X):\n",
    "        return np.argmax([ self.P[i] + sum(\n",
    "                    [norm.logpdf(x,loc=mu,scale=sig) for x,mu,sig \n",
    "                    in zip(X,self.train_label_means[i],self.train_label_vars[i])]\n",
    "                ) for i in np.unique(self.train_labels)])\n",
    "    \n",
    "    #this does the same thing... but in parallel!!! 8 times faster!\n",
    "    def naivebayes_predict_parallel(self):\n",
    "        return Parallel(n_jobs=8,verbose=5)(\n",
    "            delayed(naivebayes)(self.P,\n",
    "                                X,\n",
    "                                self.train_label_means,\n",
    "                                self.train_label_vars,\n",
    "                                2) \n",
    "            for X in self.test)\n",
    "\n",
    "    def sk_naivebayes_predict(self):\n",
    "        alg = GaussianNB()\n",
    "        alg.fit(self.train,self.train_labels)\n",
    "        return alg.predict(self.test) \n",
    "        \n",
    "    \n",
    "nb = NaiveBayes()\n",
    "print nb.D\n",
    "print nb.L\n",
    "print nb.V\n",
    "print nb.train_label_means.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "prediction01 = nb.naivebayes_predict_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.282\n"
     ]
    }
   ],
   "source": [
    "print np.sum(nb.test_labels==prediction01)/len(nb.test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sk_learn's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.282\n"
     ]
    }
   ],
   "source": [
    "prediction02 = nb.sk_naivebayes_predict()\n",
    "print np.sum(nb.test_labels==prediction01)/len(nb.test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Both methods get the exact same score! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
